{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "def transformar_fecha_hora(fecha_hora_str):\n",
    "    if isinstance(fecha_hora_str, str) and len(fecha_hora_str) == 10:\n",
    "        return f\"{fecha_hora_str[:4]}-{fecha_hora_str[4:6]}-{fecha_hora_str[6:8]}-{fecha_hora_str[8:]}:00\"\n",
    "    return fecha_hora_str # Devuelve el valor original si no tiene el formato esperado\n",
    "\n",
    "# Step 1: Read and process CSV files directly from .zip\n",
    "def process_zip_files(zip_folder, output_file, csv_files_of_interest):\n",
    "    periods = [2029, 2030, 2031, 2033, 2040, 2050]\n",
    "    counter = 0\n",
    "    for file in os.listdir(zip_folder):\n",
    "        if file.endswith(\".zip\"):\n",
    "            counter += 1\n",
    "            consolidated_data_CMg = []\n",
    "            consolidated_data_dispatch = []\n",
    "            dispatch = []\n",
    "            DispatchGen = []\n",
    "            UnservedLoad = []\n",
    "            zip_path = os.path.join(zip_folder, file)\n",
    "            print(zip_path)\n",
    "            with zipfile.ZipFile(zip_path, 'r') as archive:\n",
    "                # List all files in the ZIP archive\n",
    "                file_list = archive.namelist()\n",
    "                # Process files in the expected folder structure\n",
    "                files_of_interest = [f for f in file_list if f.endswith(tuple(csv_files_of_interest.keys()))]\n",
    "                print(f\"Archivos encontrados: {len(files_of_interest)}\")\n",
    "                for interest_file in files_of_interest:\n",
    "                    with archive.open(interest_file) as f:\n",
    "\n",
    "                        if 'marginal_cost' in interest_file:\n",
    "                            df = pd.read_csv(f, header=None, names= [\"load_zone\", \"period\", \"timepoint\", \"marginal_cost\", \"factor\"], skiprows=1)\n",
    "\n",
    "                            if len(df) == 0:\n",
    "                                continue\n",
    "                            \n",
    "                            df['timepoint'] = pd.to_datetime(df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "\n",
    "                            df = df.sort_values(by=['load_zone', 'timepoint'])\n",
    "\n",
    "                            # Calculate the difference in days between min and max timestamps\n",
    "                            min_time = df['timepoint'].min()\n",
    "                            max_time = df['timepoint'].max()\n",
    "                            days_difference = (max_time - min_time).days\n",
    "\n",
    "                            if days_difference > 7:\n",
    "                                max_month = max_time.month\n",
    "                                df = df[df['timepoint'].dt.month == max_month]\n",
    "\n",
    "                            df_first_24_hours = df.groupby('load_zone').head(24)\n",
    "                            # print(df_first_24_hours)\n",
    "                            # Append the filtered data for this file to the consolidated data list\n",
    "                            consolidated_data_CMg.append(df_first_24_hours)\n",
    "                        \n",
    "                        elif 'storage_dispatch' in interest_file or 'TES_dispatch' in interest_file:\n",
    "                            df = pd.read_csv(f, delimiter=',')\n",
    "\n",
    "                            if len(df) == 0:\n",
    "                                continue\n",
    "\n",
    "                            if \"TES_dispatch\" in interest_file:\n",
    "                                rename_map = {\"project\": \"generation_project\", \"ChargeTES_MWt\": \"ChargeMW\", \"DischargeTES_MWt\": \"DischargeMW\", \"TES_StateOfCharge_MWht\": \"StateOfCharge\"}\n",
    "                                df = df.rename(columns=rename_map)\n",
    "                                df = df[[\"generation_project\",\"timepoint\",\"load_zone\",\"ChargeMW\",\"DischargeMW\",\"StateOfCharge\"]]\n",
    "\n",
    "                            df['timepoint'] = pd.to_datetime(df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "\n",
    "                            df = df.sort_values(by=['generation_project', 'timepoint'])\n",
    "\n",
    "                            # Calculate the difference in days between min and max timepoint\n",
    "                            min_time = df['timepoint'].min()\n",
    "                            max_time = df['timepoint'].max()\n",
    "                            days_difference = (max_time - min_time).days\n",
    "\n",
    "                            if days_difference > 7:\n",
    "                                max_month = max_time.month\n",
    "                                df = df[df['timepoint'].dt.month == max_month]\n",
    "                            \n",
    "                            df_first_24_hours = df.groupby('generation_project').head(24)\n",
    "                            # print(df_first_24_hours)\n",
    "                            # Append the filtered data for this file to the consolidated data list\n",
    "                            consolidated_data_dispatch.append(df_first_24_hours)\n",
    "\n",
    "                        elif 'dispatch.csv' in interest_file:\n",
    "                            df = pd.read_csv(f, delimiter=',')\n",
    "\n",
    "                            if len(df) == 0:\n",
    "                                continue\n",
    "\n",
    "                            df = df[[\"generation_project\",\"timestamp\",\"period\",\"gen_load_zone\",\"gen_tech\",\"gen_energy_source\",\"DispatchGen_MW\",\"GenCapacity_MW\"]]\n",
    "                            \n",
    "                            df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d-%H:%M')\n",
    "\n",
    "                            df = df.sort_values(by=['generation_project', 'timestamp'])\n",
    "\n",
    "                            # Calculate the difference in days between min and max timepoint\n",
    "                            min_time = df['timestamp'].min()\n",
    "                            max_time = df['timestamp'].max()\n",
    "                            days_difference = (max_time - min_time).days\n",
    "\n",
    "                            if days_difference > 7:\n",
    "                                max_month = max_time.month\n",
    "                                df = df[df['timestamp'].dt.month == max_month]\n",
    "\n",
    "                            df_first_24_hours = df.groupby('generation_project').head(24)\n",
    "                            # print(df_first_24_hours)\n",
    "                            # Append the filtered data for this file to the consolidated data list\n",
    "                            dispatch.append(df_first_24_hours)\n",
    "\n",
    "                        elif 'DispatchGen' in interest_file:\n",
    "                            df = pd.read_csv(f, delimiter=',')\n",
    "\n",
    "                            if len(df) == 0:\n",
    "                                continue\n",
    "\n",
    "                            df = df[[\"GEN_TPS_1\",\"GEN_TPS_2\",\"DispatchGen\"]]\n",
    "                            df['GEN_TPS_2'] = df['GEN_TPS_2'].astype(str)\n",
    "                            df['GEN_TPS_2'] = df['GEN_TPS_2'].apply(transformar_fecha_hora)\n",
    "                            df['GEN_TPS_2'] = pd.to_datetime(df['GEN_TPS_2'], format='%Y-%m-%d-%H:%M')\n",
    "                            df = df.sort_values(by=['GEN_TPS_1', 'GEN_TPS_2'])\n",
    "\n",
    "                            # Calculate the difference in days between min and max timepoint\n",
    "                            min_time = df['GEN_TPS_2'].min()\n",
    "                            max_time = df['GEN_TPS_2'].max()\n",
    "                            days_difference = (max_time - min_time).days\n",
    "\n",
    "                            if days_difference > 7:\n",
    "                                max_month = max_time.month\n",
    "                                df = df[df['GEN_TPS_2'].dt.month == max_month]\n",
    "\n",
    "                            df_first_24_hours = df.groupby('GEN_TPS_1').head(24)\n",
    "                            # print(df_first_24_hours)\n",
    "                            # Append the filtered data for this file to the consolidated data list\n",
    "                            DispatchGen.append(df_first_24_hours)\n",
    "\n",
    "                        # elif 'variable_capacity_factors.csv' in interest_file:\n",
    "                        #     df = pd.read_csv(f, delimiter=',')\n",
    "\n",
    "                        #     if len(df) == 0:\n",
    "                        #         continue\n",
    "\n",
    "                        #     df = df[[\"GENERATION_PROJECT\",\"timepoint\",\"gen_max_capacity_factor\"]]\n",
    "                        #     df['timepoint'] = df['timepoint'].astype(str)\n",
    "                        #     df['timepoint'] = df['timepoint'].apply(transformar_fecha_hora)\n",
    "                        #     df['timepoint'] = pd.to_datetime(df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "                        #     df = df.sort_values(by=['GENERATION_PROJECT', 'timepoint'])\n",
    "\n",
    "                        #     # Calculate the difference in days between min and max timepoint\n",
    "                        #     min_time = df['timepoint'].min()\n",
    "                        #     max_time = df['timepoint'].max()\n",
    "                        #     days_difference = (max_time - min_time).days\n",
    "\n",
    "                        #     if days_difference > 7:\n",
    "                        #         max_month = max_time.month\n",
    "                        #         df = df[df['timepoint'].dt.month == max_month]\n",
    "\n",
    "                        #     df_first_24_hours = df.groupby('GENERATION_PROJECT').head(24)\n",
    "                        #     # print(df_first_24_hours)\n",
    "                        #     # Append the filtered data for this file to the consolidated data list\n",
    "                        #     variable_capacity_factors.append(df_first_24_hours)\n",
    "\n",
    "                        elif 'UnservedLoad' in interest_file:\n",
    "                            df = pd.read_csv(f, delimiter=',')\n",
    "\n",
    "                            if len(df) == 0:\n",
    "                                continue\n",
    "\n",
    "                            df = df[[\"SetProduct_OrderedSet_1\",\"SetProduct_OrderedSet_2\",\"UnservedLoad\"]]\n",
    "                            df['SetProduct_OrderedSet_2'] = df['SetProduct_OrderedSet_2'].astype(str)\n",
    "                            df['SetProduct_OrderedSet_2'] = df['SetProduct_OrderedSet_2'].apply(transformar_fecha_hora)\n",
    "                            df['SetProduct_OrderedSet_2'] = pd.to_datetime(df['SetProduct_OrderedSet_2'], format='%Y-%m-%d-%H:%M')\n",
    "                            df = df.sort_values(by=['SetProduct_OrderedSet_1', 'SetProduct_OrderedSet_2'])\n",
    "\n",
    "                            # Calculate the difference in days between min and max timepoint\n",
    "                            min_time = df['SetProduct_OrderedSet_2'].min()\n",
    "                            max_time = df['SetProduct_OrderedSet_2'].max()\n",
    "                            days_difference = (max_time - min_time).days\n",
    "\n",
    "                            if days_difference > 7:\n",
    "                                max_month = max_time.month\n",
    "                                df = df[df['SetProduct_OrderedSet_2'].dt.month == max_month]\n",
    "\n",
    "                            df_first_24_hours = df.groupby('SetProduct_OrderedSet_1').head(24)\n",
    "                            # print(df_first_24_hours)\n",
    "                            # Append the filtered data for this file to the consolidated data list\n",
    "                            UnservedLoad.append(df_first_24_hours)\n",
    "\n",
    "            # Combine all data into a single DataFrame\n",
    "            if consolidated_data_CMg:\n",
    "                result_df = pd.concat(consolidated_data_CMg, ignore_index=False)\n",
    "                # result_df['timepoint'] = pd.to_datetime(result_df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "                result_df = result_df.sort_values(by=['load_zone', 'timepoint'])\n",
    "                result_df.to_csv(os.path.join(zip_folder, f\"consolidated_marginal_cost_{periods[counter-1]}.csv\"), index=False)\n",
    "                print(f\"Consolidated data saved to consolidated_marginal_cost_{counter}.csv\")\n",
    "            else:\n",
    "                print(\"No data to consolidate.\")\n",
    "\n",
    "            if consolidated_data_dispatch:\n",
    "                result_df = pd.concat(consolidated_data_dispatch, ignore_index=False)\n",
    "                # result_df['timepoint'] = pd.to_datetime(result_df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "                result_df = result_df.sort_values(by=['generation_project', 'timepoint'])\n",
    "                result_df.to_csv(os.path.join(zip_folder, f\"consolidated_dispatch_{periods[counter-1]}.csv\"), index=False)\n",
    "                print(f\"Consolidated data saved to consolidated_dispatch_{counter}.csv\")\n",
    "            else:\n",
    "                print(\"No data to consolidate.\")\n",
    "\n",
    "            if dispatch:\n",
    "                result_df = pd.concat(dispatch, ignore_index=False)\n",
    "                # result_df['timepoint'] = pd.to_datetime(result_df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "                result_df = result_df.sort_values(by=['generation_project', 'timestamp'])\n",
    "                result_df.to_csv(os.path.join(zip_folder, f\"dispatch_{periods[counter-1]}.csv\"), index=False)\n",
    "                print(f\"Consolidated data saved to dispatch_{counter}.csv\")\n",
    "            else:\n",
    "                print(\"No data to consolidate.\")\n",
    "\n",
    "            if DispatchGen:\n",
    "                result_df = pd.concat(DispatchGen, ignore_index=False)\n",
    "                # result_df['timepoint'] = pd.to_datetime(result_df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "                result_df = result_df.sort_values(by=['GEN_TPS_1', 'GEN_TPS_2'])\n",
    "                result_df.to_csv(os.path.join(zip_folder, f\"DispatchGen_{periods[counter-1]}.csv\"), index=False)\n",
    "                print(f\"Consolidated data saved to DispatchGen_{counter}.csv\")\n",
    "            else:\n",
    "                print(\"No data to consolidate.\")\n",
    "            \n",
    "            # if variable_capacity_factors:\n",
    "            #     result_df = pd.concat(variable_capacity_factors, ignore_index=False)\n",
    "            #     # result_df['timepoint'] = pd.to_datetime(result_df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "            #     result_df = result_df.sort_values(by=['GENERATION_PROJECT', 'timepoint'])\n",
    "            #     result_df.to_csv(os.path.join(zip_folder, f\"variable_capacity_factors_{periods[counter-1]}.csv\"), index=False)\n",
    "            #     print(f\"Consolidated data saved to variable_capacity_factors_{counter}.csv\")\n",
    "            # else:\n",
    "            #     print(\"No data to consolidate.\")\n",
    "\n",
    "            if UnservedLoad:\n",
    "                result_df = pd.concat(UnservedLoad, ignore_index=False)\n",
    "                # result_df['timepoint'] = pd.to_datetime(result_df['timepoint'], format='%Y-%m-%d-%H:%M')\n",
    "                result_df = result_df.sort_values(by=['SetProduct_OrderedSet_1', 'SetProduct_OrderedSet_2'])\n",
    "                result_df.to_csv(os.path.join(zip_folder, f\"UnservedLoad_{periods[counter-1]}.csv\"), index=False)\n",
    "                print(f\"Consolidated data saved to UnservedLoad_{counter}.csv\")\n",
    "            else:\n",
    "                print(\"No data to consolidate.\")\n",
    "\n",
    "# Paths (modify these as needed)\n",
    "# zip_folder = os.path.join(\"d:/Github/switch_uai_scripts\", \"Modelos_SEN_finals/EEN 1 EEC 1 (Transicion Acelerada)\")     # Folder containing .zip files\n",
    "zip_folder = os.path.join(r\"C:/Users/Ignac/Trabajo_Centra/Catedra-LDES/CII-Centra-EDF/Operacion\", r\"escenarios/CaseBase1/TA/\")\n",
    "print(zip_folder)\n",
    "# zip_folder = os.path.join(\"d:/Github/switch_uai_scripts\", \"Modelos_SEN_finals/EEN -1 EEC -1 (Recuperacion Lenta)\")\n",
    "csv_files_of_interest = {\n",
    "    \"outputs_dispatch/marginal_cost.csv\": {\n",
    "        \"columns\": [\"load_zone\", \"period\", \"timepoint\", \"marginal_cost\", \"factor\"],\n",
    "        \"skiprows\": 1\n",
    "    },\n",
    "    \"outputs_dispatch/storage_dispatch.csv\": {\n",
    "        \"columns\": [\"generation_project\",\"timepoint\",\"load_zone\",\"ChargeMW\",\"DischargeMW\",\"StateOfCharge\"],\n",
    "        \"skiprows\": None\n",
    "    },\n",
    "    \"outputs_dispatch/TES_dispatch.txt\": {\n",
    "        \"columns\": [\"generation_project\",\"timepoint\",\"load_zone\",\"ChargeMW\",\"DischargeMW\",\"StateOfCharge\"],\n",
    "        \"skiprows\": None\n",
    "    },\n",
    "    \"outputs_dispatch/dispatch.csv\": {\n",
    "        \"columns\": [\"generation_project\",\"timestamp\",\"period\",\"gen_load_zone\",\"gen_tech\",\"gen_energy_source\",\"DispatchGen_MW\",\"GenCapacity_MW\"],\n",
    "        \"skiprows\": None\n",
    "    },\n",
    "    \"outputs_dispatch/DispatchGen.csv\": {\n",
    "        \"columns\": [\"GEN_TPS_1\",\"GEN_TPS_2\",\"DispatchGen\"],\n",
    "        \"skiprows\": None\n",
    "    },\n",
    "    \"outputs_dispatch/UnservedLoad.csv\": {\n",
    "        \"columns\": [\"SetProduct_OrderedSet_1\",\"SetProduct_OrderedSet_2\",\"UnservedLoad\"],\n",
    "        \"skiprows\": None\n",
    "    },\n",
    "    # \"inputs_dispacth/variable_capacity_factors.csv\": {\n",
    "    #     \"columns\": [\"GENERATION_PROJECT\",\"timepoint\",\"gen_max_capacity_factor\"],\n",
    "    #     \"skiprows\": None\n",
    "    # },\n",
    "}\n",
    "# csv_files_of_interest = [\"outputs_dispatch/marginal_cost.csv\"]#, \"outputs_dispatch/storage_dispatch.csv\"]  # CSV files to process\n",
    "os.listdir(zip_folder)\n",
    "output_file = \"consolidated_data.csv\"  # Output file for consolidated data\n",
    "# Run the process\n",
    "process_zip_files(zip_folder, output_file, csv_files_of_interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(\"D:\\Github\\switch_uai_scripts\\Modelos_SEN_finals\\EEN 0 EEC 0 (Rumbo CNprueba)\\outputs\", \"TES_dispatch.txt\"))\n",
    "len(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
